# Pub-Sub Log Aggregator

Sistem Pub-Sub log aggregator multi-service dengan Docker Compose yang mendukung **idempotency**, **deduplication**, dan **transaksi/kontrol konkurensi**.

## ğŸ“„ Dokumentasi

- **[Laporan Lengkap (report/report.pdf)](report/report.pdf)**: Teori (T1-T10), implementasi, dan analisis performa
- **[Video Demo](https://youtu.be/AcT1KDS0pMc)**: Demo sistem lengkap (arsitektur, dedup, transaksi, persistensi)

Untuk compile laporan ke PDF:

```bash
cd report && typst compile report.typ
```

## Arsitektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Publisher    â”‚â”€â”€â”€â”€â–¶â”‚      Redis      â”‚â—€â”€â”€â”€â”€â”‚   Aggregator    â”‚
â”‚  (Generator)    â”‚     â”‚    (Broker)     â”‚     â”‚   (FastAPI)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â”‚
                                                         â–¼
                                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                â”‚   PostgreSQL    â”‚
                                                â”‚   (Storage)     â”‚
                                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Komponen

- **Aggregator**: API FastAPI untuk menerima dan memproses event; consumer internal
- **Publisher**: Generator event dengan duplikasi (â‰¥35%)
- **Broker**: Redis 7 sebagai message queue internal
- **Storage**: PostgreSQL 18 dengan constraint unik untuk deduplication atomik

## Teknologi

| Komponen | Teknologi |
|----------|-----------|
| Language | Python 3.14 |
| Framework | FastAPI + asyncio |
| Package Manager | uv |
| Database | PostgreSQL 18 |
| Message Broker | Redis 7 |
| Type Checking | basedpyright (strict) |
| Container | Docker Compose |

## Quick Start

### 1. Build dan Jalankan

```bash
# Build semua image dan start services
docker compose up --build -d

# Lihat status containers
docker compose ps

# Lihat logs aggregator
docker compose logs -f aggregator
```

### 2. Test Endpoints

```bash
# Health check
curl http://localhost:8080/health

# Publish single event
curl -X POST http://localhost:8080/publish \
  -H "Content-Type: application/json" \
  -d '{
    "topic": "logs",
    "event_id": "evt-001",
    "timestamp": "2024-01-01T00:00:00Z",
    "source": "app-1",
    "payload": {"message": "Hello"}
  }'

# Publish batch
curl -X POST http://localhost:8080/publish/batch \
  -H "Content-Type: application/json" \
  -d '{
    "events": [
      {"topic": "logs", "event_id": "evt-002", "timestamp": "2024-01-01T00:00:01Z", "source": "app-1", "payload": {}},
      {"topic": "logs", "event_id": "evt-003", "timestamp": "2024-01-01T00:00:02Z", "source": "app-1", "payload": {}}
    ]
  }'

# Get events (filtered by topic)
curl "http://localhost:8080/events?topic=logs"

# Get statistics
curl http://localhost:8080/stats
```

### 3. Jalankan Publisher (Load Test)

```bash
# Publisher akan otomatis berjalan dan mengirim 25k events
docker compose logs -f publisher
```

### 4. Stop Services

```bash
# Stop (data persists)
docker compose stop

# Remove containers (volumes preserved)
docker compose down

# Remove everything including volumes
docker compose down -v
```

## API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/publish` | Publish single event |
| POST | `/publish/batch` | Publish batch of events |
| GET | `/events?topic=X` | Get processed events |
| GET | `/stats` | Get statistics (received, unique, duplicates, uptime) |
| GET | `/health` | Health check |

### Event Schema

```json
{
  "topic": "string (required, 1-255 chars)",
  "event_id": "string (required, unique per topic)",
  "timestamp": "ISO8601 datetime (required)",
  "source": "string (required)",
  "payload": "object (optional)"
}
```

## Idempotency & Deduplication

Sistem menggunakan **INSERT ... ON CONFLICT DO NOTHING** dengan unique constraint pada `(topic, event_id)`:

```sql
INSERT INTO processed_events (topic, event_id, timestamp, source, payload)
VALUES ($1, $2, $3, $4, $5)
ON CONFLICT (topic, event_id) DO NOTHING
RETURNING id
```

### Isolation Level

- **READ COMMITTED** dengan unique constraints
- Trade-off: High throughput dengan jaminan tidak ada duplicate processing
- Atomic stats update: `UPDATE stats SET count = count + N`

## Testing

### Run Tests

```bash
# Start storage dan broker terlebih dahulu
docker compose up -d storage broker
docker compose up -d aggregator

# Tunggu services ready
sleep 10

# Install test dependencies
cd tests && uv sync

# Run all tests
uv run pytest -v

# Run specific test category
uv run pytest test_dedup.py -v
uv run pytest test_concurrency.py -v
uv run pytest test_stress.py -v
```

### Test Coverage (23 tests)

| Category | Tests | Description |
|----------|-------|-------------|
| Deduplication | 4 | Single/batch duplicates, different topics |
| API | 10 | Endpoints, validation, error handling |
| Concurrency | 4 | Parallel workers, race conditions |
| Persistence | 3 | Data durability, restart recovery |
| Stress | 3 | 20k events, throughput measurement |

**Total: 23 tests passing**

## Performance

Target: â‰¥20,000 events dengan â‰¥30% duplikasi

| Metric | Value |
|--------|-------|
| Throughput | ~1000+ events/second |
| Duplicate Rate | 35% injected |
| Batch Size | 100-200 events |

## Persistensi Data

Data disimpan di named volumes:

```yaml
volumes:
  pg_data:      # PostgreSQL data
  broker_data:  # Redis AOF persistence
```

### Verifikasi Persistensi

```bash
# Check stats
curl http://localhost:8080/stats

# Destroy containers
docker compose down

# Recreate
docker compose up -d

# Stats should persist!
curl http://localhost:8080/stats
```

## Development

### Type Checking

```bash
cd aggregator && uv run basedpyright app/
cd publisher && uv run basedpyright app/
```

### Local Development

```bash
# Install dependencies
cd aggregator && uv sync
cd publisher && uv sync

# Run locally (needs external postgres/redis)
DATABASE_URL=postgresql://... BROKER_URL=redis://... uv run uvicorn app.main:app --reload
```

## Struktur Direktori

```
pub-sub-log-aggregator/
â”œâ”€â”€ aggregator/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”œâ”€â”€ py.typed
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ main.py        # FastAPI entry
â”‚       â”œâ”€â”€ config.py      # Settings
â”‚       â”œâ”€â”€ models.py      # Pydantic models
â”‚       â”œâ”€â”€ database.py    # PostgreSQL + transactions
â”‚       â”œâ”€â”€ consumer.py    # Idempotent consumer
â”‚       â””â”€â”€ routes.py      # API routes
â”œâ”€â”€ publisher/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”œâ”€â”€ py.typed
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ main.py        # Entry point
â”‚       â”œâ”€â”€ config.py      # Settings
â”‚       â””â”€â”€ generator.py   # Event generator
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ test_dedup.py
â”‚   â”œâ”€â”€ test_api.py
â”‚   â”œâ”€â”€ test_concurrency.py
â”‚   â”œâ”€â”€ test_persistence.py
â”‚   â””â”€â”€ test_stress.py
â”œâ”€â”€ init-db/
â”‚   â””â”€â”€ init.sql           # Schema initialization
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

## Keputusan Desain

1. **PostgreSQL vs Redis untuk dedup store**: PostgreSQL dipilih karena ACID transactions dan unique constraints yang kuat
2. **READ COMMITTED isolation**: Balance antara performance dan consistency; unique constraints mencegah duplicates
3. **INSERT ON CONFLICT DO NOTHING**: Atomic deduplication tanpa locking eksplisit
4. **Batch processing**: Throughput lebih tinggi dengan transactional batch inserts
5. **Background consumer optional**: Direct processing untuk simplicity, queue tersedia untuk scaling
